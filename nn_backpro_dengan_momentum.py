# -*- coding: utf-8 -*-
"""nn-backpro-dengan-momentum.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mNeD0Nky3w47_aCX7DQfRa-OhVt902Sd
"""

import numpy as np

# Fungsi aktivasi sigmoid
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivatif dari fungsi sigmoid
def sigmoid_derivative(x):
    return sigmoid(x) * (1 - sigmoid(x))

# Inisialisasi bobot secara acak
def initialize_weights(input_size, hidden_size, output_size):
    W1 = np.random.randn(hidden_size, input_size)
    b1 = np.random.randn(hidden_size, 1)
    W2 = np.random.randn(output_size, hidden_size)
    b2 = np.random.randn(output_size, 1)

    weights = {"W1": W1, "b1": b1, "W2": W2, "b2": b2}
    return weights

# Fungsi feedforward
def feedforward(X, weights):
    W1 = weights["W1"]
    b1 = weights["b1"]
    W2 = weights["W2"]
    b2 = weights["b2"]

    Z1 = np.dot(W1, X) + b1
    A1 = sigmoid(Z1)
    Z2 = np.dot(W2, A1) + b2
    A2 = sigmoid(Z2)

    activations = {"A1": A1, "A2": A2}
    return activations

# Fungsi backpropagation
def backpropagation(X, Y, activations, weights, learning_rate, momentum):
    A1 = activations["A1"]
    A2 = activations["A2"]
    W2 = weights["W2"]

    dZ2 = A2 - Y
    dW2 = np.dot(dZ2, A1.T) / X.shape[1]
    db2 = np.mean(dZ2, axis=1, keepdims=True)

    dZ1 = np.dot(W2.T, dZ2) * sigmoid_derivative(A1)
    dW1 = np.dot(dZ1, X.T) / X.shape[1]
    db1 = np.mean(dZ1, axis=1, keepdims=True)

    # Update bobot dan bias dengan momentum
    dW2_prev = weights.get("dW2_prev", 0)
    db2_prev = weights.get("db2_prev", 0)
    dW1_prev = weights.get("dW1_prev", 0)
    db1_prev = weights.get("db1_prev", 0)

    dW2_prev = momentum * dW2_prev + (1 - momentum) * dW2
    db2_prev = momentum * db2_prev + (1 - momentum) * db2
    dW1_prev = momentum * dW1_prev + (1 - momentum) * dW1
    db1_prev = momentum * db1_prev + (1 - momentum) * db1

    weights["W2"] -= learning_rate * dW2_prev
    weights["b2"] -= learning_rate * db2_prev
    weights["W1"] -= learning_rate * dW1_prev
    weights["b1"] -= learning_rate * db1_prev

    weights["dW2_prev"] = dW2_prev
    weights["db2_prev"] = db2_prev
    weights["dW1_prev"] = dW1_prev
    weights["db1_prev"] = db1_prev

    return weights

# Fungsi untuk menghitung MSE
def compute_mse(X, Y, weights):
    activations = feedforward(X, weights)
    A2 = activations["A2"]
    mse = np.mean((A2 - Y) ** 2)
    return mse

# Algoritma pembelajaran
def train(X, Y, hidden_size, max_epoch, target_error, learning_rate, momentum):
    input_size = X.shape[0]
    output_size = Y.shape[0]

    weights = initialize_weights(input_size, hidden_size, output_size)
    epoch = 0
    mse = float("inf")
    mse_history = []

    while epoch < max_epoch and mse > target_error:
        epoch += 1
        mse = 0

        for i in range(X.shape[1]):
            x = X[:, i].reshape(-1, 1)
            y = Y[:, i].reshape(-1, 1)

            activations = feedforward(x, weights)
            weights = backpropagation(x, y, activations, weights, learning_rate, momentum)

            mse += compute_mse(x, y, weights)

        mse /= X.shape[1]
        mse_history.append(mse)

        print("Epoch {}: MSE = {}".format(epoch, mse))

    return weights, mse_history

# Contoh penggunaan
X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])
Y = np.array([[0, 1, 1, 0]])

hidden_size = 3
max_epoch = 10000
target_error = 0.01
learning_rate = 0.1
momentum = 0.97

weights, mse_history = train(X, Y, hidden_size, max_epoch, target_error, learning_rate, momentum)

# Prediksi
activations = feedforward(X, weights)
predictions = np.round(activations["A2"])
print("Prediksi: {}".format(predictions))

# Plot grafik pembelajaran
import matplotlib.pyplot as plt

plt.plot(range(len(mse_history)), mse_history)
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.title("Grafik Pembelajaran")
plt.show()